{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538707ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import time\n",
    "import shutil\n",
    "import wandb\n",
    "import logging\n",
    "import imgaug as ia\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from imgaug import augmenters as iaa\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from util import util\n",
    "from UNet3D.config import (\n",
    "    TRAINING_EPOCH, NUM_CLASSES, IN_CHANNELS, BCE_WEIGHTS, BACKGROUND_AS_CLASS, TRAIN_CUDA\n",
    ")\n",
    "from UNet3D.unet3d import UNet3D\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from models.networks import arch_parameters\n",
    "from transforms import fake_transform\n",
    "from util.util import zero_division\n",
    "\n",
    "from betty.engine import Engine\n",
    "from betty.configs import Config, EngineConfig\n",
    "from betty.problems import ImplicitProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d09838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.base_dataset import BaseDataset, get_params_3d, get_transform_torchio\n",
    "import os\n",
    "import torchio\n",
    "import torch\n",
    "import pandas as pd\n",
    "from util.util import error, nifti_to_np\n",
    "\n",
    "\n",
    "class VestibularDataset(BaseDataset):\n",
    "    @staticmethod\n",
    "    def modify_commandline_options(parser, is_train):\n",
    "        parser.add_argument('--csv_path', type=str, required=True, help='Path to the CSV file containing image, mask, and class information.')\n",
    "        parser.set_defaults(input_nc=1, output_nc=1) # Assuming single channel for MRI images and masks\n",
    "        return parser\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        BaseDataset.__init__(self, opt)\n",
    "        self.csv_path = opt.csv_path\n",
    "        self.data_frame = pd.read_csv(self.csv_path)\n",
    "\n",
    "        self.image_paths = self.data_frame['Image'].tolist()\n",
    "        self.mask_paths = self.data_frame['Mask'].tolist()\n",
    "        self.classes = self.data_frame['Class'].tolist()\n",
    "\n",
    "        # Map 'decreasing' to 0 and 'increasing' to 1\n",
    "        self.class_mapping = {'decreasing': 0, 'increasing': 1}\n",
    "\n",
    "        self.original_shape = None\n",
    "        self.affine = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        mask_path = self.mask_paths[index]\n",
    "        class_label_str = self.classes[index]\n",
    "        class_label = self.class_mapping[class_label_str]\n",
    "\n",
    "        # Load MRI image and mask using nifti_to_np (assuming NIfTI format)\n",
    "        # For 3D data, sliced=False\n",
    "        image_np, affine = nifti_to_np(image_path, sliced=False, chosen_slice=None)\n",
    "        mask_np, _ = nifti_to_np(mask_path, sliced=False, chosen_slice=None)\n",
    "\n",
    "        self.original_shape = image_np.shape\n",
    "        self.affine = affine\n",
    "\n",
    "        # Convert numpy arrays to TorchIO Image and LabelMap\n",
    "        # TorchIO expects (C, H, W, D) or (H, W, D) for 3D, and nifti_to_np returns (H, W, D)\n",
    "        # So we need to add a channel dimension\n",
    "        image_tio = torchio.Image(tensor=image_np[None, ...], affine=affine, type=torchio.INTENSITY)\n",
    "        mask_tio = torchio.LabelMap(tensor=mask_np[None, ...], affine=affine)\n",
    "        \n",
    "        # Apply transformations. Assuming 3D transforms are needed for MRI.\n",
    "        transform_params = get_params_3d(self.opt, image_tio.shape)\n",
    "        c_transform = get_transform_torchio(self.opt, transform_params)\n",
    "\n",
    "        image_transformed = c_transform(image_tio)\n",
    "        mask_transformed = c_transform(mask_tio)\n",
    "\n",
    "        # Ensure mask is binary (0 or 1)\n",
    "        mask_transformed.data = (mask_transformed.data > 0).float()\n",
    "\n",
    "\n",
    "        return {\n",
    "            'A': image_transformed.data,  # Input image\n",
    "            'mask': mask_transformed.data, # Corresponding mask\n",
    "            'class_label': torch.tensor(class_label, dtype=torch.long), # Class label as tensor\n",
    "            'A_paths': image_path,\n",
    "            'mask_paths': mask_path\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff8995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd57ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: flipped_outputs\\image_flip_axis0.nii.gz\n",
      "Saved: flipped_outputs\\label_flip_axis0.nii.gz\n",
      "Saved: flipped_outputs\\image_flip_axis1.nii.gz\n",
      "Saved: flipped_outputs\\label_flip_axis1.nii.gz\n",
      "Saved: flipped_outputs\\image_flip_axis2.nii.gz\n",
      "Saved: flipped_outputs\\label_flip_axis2.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- RandomFlip class (unchanged) ---\n",
    "class RandomFlip:\n",
    "    \"\"\"Randomly flips along the specified axis.\"\"\"\n",
    "    def __init__(self, prob=0.5, spatial_axis=0):\n",
    "        self.prob = prob\n",
    "        self.axis = spatial_axis\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        if torch.rand(1).item() < self.prob:\n",
    "            image = torch.flip(image, dims=[self.axis])\n",
    "            label = torch.flip(label, dims=[self.axis])\n",
    "        return {'image': image, 'label': label}\n",
    "\n",
    "\n",
    "# --- Load NIfTI file ---\n",
    "def load_nifti(filepath):\n",
    "    nifti_img = nib.load(filepath)\n",
    "    data = nifti_img.get_fdata()\n",
    "    affine = nifti_img.affine\n",
    "    return data, affine\n",
    "\n",
    "\n",
    "# --- Save NIfTI file ---\n",
    "def save_nifti(data, affine, out_path):\n",
    "    nifti_img = nib.Nifti1Image(data, affine)\n",
    "    nib.save(nifti_img, out_path)\n",
    "    print(f\"Saved: {out_path}\")\n",
    "\n",
    "\n",
    "# --- Main pipeline ---\n",
    "def apply_flip_and_save(image_path, label_path, axis_list=[0, 1, 2], prob=1.0, output_dir='flipped_outputs'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load image and label\n",
    "    image_np, affine = load_nifti(image_path)\n",
    "    label_np, _ = load_nifti(label_path)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    image_tensor = torch.tensor(image_np, dtype=torch.float32)\n",
    "    label_tensor = torch.tensor(label_np, dtype=torch.float32)\n",
    "\n",
    "    # Apply flip on each axis\n",
    "    for axis in axis_list:\n",
    "        flipper = RandomFlip(prob=prob, spatial_axis=axis)\n",
    "        flipped = flipper({'image': image_tensor, 'label': label_tensor})\n",
    "\n",
    "        # Convert back to NumPy\n",
    "        flipped_img = flipped['image'].numpy()\n",
    "        flipped_lbl = flipped['label'].numpy()\n",
    "\n",
    "        # Save outputs for visualization in 3D Slicer\n",
    "        save_nifti(flipped_img, affine, os.path.join(output_dir, f'image_flip_axis{axis}.nii.gz'))\n",
    "        save_nifti(flipped_lbl, affine, os.path.join(output_dir, f'label_flip_axis{axis}.nii.gz'))\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Replace these paths with your own NIfTI files\n",
    "image_path = r'C:\\Users\\nikit\\Downloads\\vs_gk_0000.nii'\n",
    "label_path = r'C:\\Users\\nikit\\Downloads\\Struct_TUMOR.nii'\n",
    "\n",
    "apply_flip_and_save(image_path, label_path, axis_list=[0, 1, 2], prob=1.0)  # set prob=1.0 to always flip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb94875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenSeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
