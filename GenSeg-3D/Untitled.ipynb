{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e018a803-7917-4cfd-9a04-ab75ebe9f75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dominate\n",
      "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: dominate\n",
      "Successfully installed dominate-2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dominate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54693721-a497-4a17-8303-d6c1b9faff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from models.networks import arch_parameters\n",
    "from util.visualizer import Visualizer\n",
    "from util.util import print_timestamped\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0879f24-c45b-422e-bfb2-0ab1b05cfada",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    opt = TrainOptions().parse()  # get training options\n",
    "    # Since the 3d training is very intense, we don't print\n",
    "    if opt.model == \"pix2pix3d\":\n",
    "        opt.display_id = -1\n",
    "    data_loader = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "    dataset = data_loader.dataset\n",
    "    total_size = len(dataset)\n",
    "    split_1 = 98\n",
    "    split_2 = total_size - split_1\n",
    "    # Perform the split\n",
    "    subset1, subset2 = random_split(dataset, [split_1, split_2])\n",
    "    dataset = DataLoader(subset1, batch_size=opt.batch_size, num_workers=int(opt.num_threads), shuffle=not opt.serial_batches)\n",
    "    \n",
    "    dataset_size = len(dataset)  # get the number of images in the dataset.\n",
    "    print('The number of training images = %d' % dataset_size)\n",
    "    model = create_model(opt)  # create a model given opt.model and other options\n",
    "    model.setup(opt)  # regular setup: load and print networks; create schedulers\n",
    "    # Print network information\n",
    "    if opt.print_model_info and \"pix2pix\" in opt.model:\n",
    "        from torchsummary import summary\n",
    "        final_size = opt.crop_size if \"crop\" in opt.preprocess else opt.load_size\n",
    "        if \"3d\" in opt.model:\n",
    "            summary(model.netG, (opt.input_nc, final_size, final_size, final_size))\n",
    "        else:\n",
    "            summary(model.netG, (opt.input_nc, final_size, final_size))\n",
    "    visualizer = Visualizer(opt)  # create a visualizer that display/save images and plots\n",
    "    total_iters = 0  # the total number of training iterations\n",
    "    init_time = time.time()\n",
    "    \n",
    "    for epoch in range(opt.epoch_count,\n",
    "                       opt.n_epochs + opt.n_epochs_decay + 1):  # outer loop for different epochs;\n",
    "        # we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "        epoch_start_time = time.time()  # timer for entire epoch\n",
    "        iter_data_time = time.time()  # timer for data loading per iteration\n",
    "        epoch_iter = 0  # the number of training iterations in current epoch, reset to 0 every epoch\n",
    "        visualizer.reset()  # reset the visualizer: make sure it saves the results to HTML at least once every epoch\n",
    "\n",
    "        for i, data in enumerate(dataset):  # inner loop within one epoch\n",
    "            iter_start_time = time.time()  # timer for computation per iteration\n",
    "            if total_iters % opt.print_freq == 0:\n",
    "                t_data = iter_start_time - iter_data_time\n",
    "\n",
    "            total_iters += opt.batch_size\n",
    "            epoch_iter += opt.batch_size\n",
    "            model.set_input(data)  # unpack data from dataset and apply preprocessing\n",
    "            model.optimize_parameters()  # calculate loss functions, get gradients, update network weights\n",
    "\n",
    "            if total_iters % opt.display_freq == 0:  # display images on visdom and save images to a HTML file\n",
    "                save_result = total_iters % opt.update_html_freq == 0\n",
    "                model.compute_visuals()\n",
    "                visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n",
    "\n",
    "            if total_iters % opt.print_freq == 0:  # print training losses and save logging information to the disk\n",
    "                losses = model.get_current_losses()\n",
    "                t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
    "                visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)\n",
    "                if opt.display_id > 0:\n",
    "                    visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, losses)\n",
    "\n",
    "            if total_iters % opt.save_latest_freq == 0:  # cache our latest model every <save_latest_freq> iterations\n",
    "                print('saving the latest model (epoch %d, total_iters %d)' % (epoch, total_iters))\n",
    "                save_suffix = 'iter_%d' % total_iters if opt.save_by_iter else 'latest'\n",
    "                model.save_networks(save_suffix)\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "        model.update_learning_rate()  # update learning rates in the end of every epoch.\n",
    "        if epoch % opt.save_epoch_freq == 0:  # cache our model every <save_epoch_freq> epochs\n",
    "            print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "            model.save_networks('latest')\n",
    "            model.save_networks(epoch)\n",
    "\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d sec' % (\n",
    "            epoch, opt.n_epochs + opt.n_epochs_decay, time.time() - epoch_start_time))\n",
    "    torch.save(arch_parameters(), model.save_dir + \"/arch_parameters.pth\")\n",
    "    end_time = round(time.time() - init_time, 3)\n",
    "    print_timestamped(\"The training process took \" + str(end_time) + \"s.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GenSeg]",
   "language": "python",
   "name": "conda-env-GenSeg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
